# ğŸ‘— Style Finder: AI-Powered Fashion Analysis Web App

**Style Finder** is an AI-driven, multimodal Retrieval-Augmented Generation (RAG) system that analyzes fashion images and provides catalog-style clothing insights in real time. Built using computer vision, vector similarity search, and the Meta LLaMA 3.2 90B Vision Instruct model, this project delivers intelligent recommendations and analysis of fashion items inspired by Taylor Swiftâ€™s iconic wardrobe.

![Style Finder Demo](https://user-images.githubusercontent.com/your-gif-or-image.gif)

---

## ğŸš€ Features

- ğŸ–¼ï¸ Upload a fashion image and receive a full catalog-style analysis
- ğŸ¤– Combines ResNet50 + Vision LLM (LLaMA 3.2) for multimodal reasoning
- ğŸ” Finds visually similar outfits via cosine similarity search
- ğŸ›ï¸ Returns real product names, prices, and purchase links
- ğŸ’¬ Generates markdown-formatted descriptions using Watsonx LLM
- ğŸ§  Built using modular, scalable architecture (CV + RAG + LLM)
- ğŸŒ Interactive interface with [Gradio](https://www.gradio.app/)

---

## ğŸ“· Sample Use Case

> Upload an image of an outfit. The system identifies its visual elements (color, pattern, material), compares it to a Taylor Swift-inspired dataset, and outputs:
>
> - Garment descriptions
> - Outfit style (e.g. casual, formal)
> - Similar purchasable items with prices & links

---

## ğŸ§  Tech Stack

| Component        | Tool/Library                                  |
|------------------|-----------------------------------------------|
| ğŸ‘ï¸ Computer Vision | ResNet50 (TorchVision)                        |
| ğŸ§  LLM Model       | Meta LLaMA 3.2 Vision Instruct via IBM Watsonx |
| ğŸ” Retrieval       | Cosine similarity with Scikit-Learn           |
| ğŸ§¾ UI Interface    | Gradio Blocks UI                              |
| ğŸ§ª Dataset         | Curated from [TaylorSwiftStyle.com](https://taylorswiftstyle.com/) |
| ğŸ—‚ï¸ File Format     | Pre-encoded `.pkl` with image embeddings      |

---

## ğŸ› ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/style-finder-ai.git
cd style-finder-ai
```
### 2. Create a Virtual Environment

```bash
python3.11 -m venv venv
source venv/bin/activate   # For Mac/Linux
# OR
venv\Scripts\activate      # For Windows
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Create a .env File
```bash
API_KEY=your_ibm_api_key
PROJECT_ID=your_project_id
REGION=us-south
```

### 5. Download the Dataset
```bash
curl -o swift-style-embeddings.pkl https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/95eJ0YJVtqTZhEd7RaUlew/processed-swift-style-with-embeddings.pkl
```

---

## ğŸš¦ Run the App Locally
```bash
python app.py
```

---

## How it works?
### ğŸ§  Multimodal RAG Pipeline â€” Step-by-Step Workflow

1ï¸âƒ£ **Image â†’ Vector Embedding (ResNet50)**  
ğŸ“· User uploads a fashion image  
ğŸ” Passed through **pretrained ResNet50**  
ğŸ“ Extracts high-dimensional **feature embeddings**  
ğŸ§¬ Output: A unique vector representation of the image

â†“

2ï¸âƒ£ **Vector Similarity Search (Scikit-learn + `.pkl`)**  
ğŸ“¦ Precomputed `.pkl` file contains embeddings of **Taylor Swift-inspired outfits**  
ğŸ§® **Cosine similarity** measures closeness to user image embedding  
ğŸ” Top-N **visually similar outfits** are retrieved  
ğŸ“‹ Metadata includes: title, price, description, and shopping links

â†“

3ï¸âƒ£ **Structured Prompt Construction (Markdown + Metadata)**  
ğŸ› ï¸ Metadata of matched items is formatted using **Python helper functions**  
ğŸ§¾ Output is a **structured markdown prompt** (like a product catalog)  
ğŸ§  Serves as **contextual memory** for the LLM

â†“

4ï¸âƒ£ **Multimodal Reasoning with LLaMA 3.2 Vision Instruct (Watsonx.ai)**  
ğŸ“¤ Input to LLM includes:  
   - ğŸ–¼ï¸ User Image  
   - ğŸ“„ Markdown Context  
   - âœï¸ Task prompt:  
     _"Describe the style of this outfit, name the clothing pieces, and suggest similar alternatives."_  
ğŸ¤– **LLaMA 3.2 Vision Instruct** processes both text + image  
ğŸ§  Generates **catalog-style response** via multimodal reasoning

â†“

5ï¸âƒ£ **Real-Time Output via Gradio**  
ğŸŒ Output is displayed in an **interactive Gradio web app**  
âœ¨ Shows:  
   - Style description  
   - Clothing names, prices, and links  
   - ğŸ‘— Alternative outfit suggestions
 
### ğŸ“Œ Credits

- ğŸ’¡ Original concept by **IBM watsonx Multimodal AI Labs**
- ğŸ§  LLM model: **Meta LLaMA 3.2 90B Vision Instruct** via [Watsonx.ai](https://www.ibm.com/watsonx)
- ğŸ‘— Dataset inspired by [TaylorSwiftStyle.com](https://taylorswiftstyle.com)
- ğŸ’» Built and customized by **Saniel Bhattarai**